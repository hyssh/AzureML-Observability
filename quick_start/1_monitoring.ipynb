{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aml_obs.drift import Drift_Analysis\n",
    "from aml_obs.collector import Online_Collector\n",
    "from aml_obs.query import RT_Visualization\n",
    "from azureml.core import Workspace\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "drift_analysis = Drift_Analysis(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest streaming data  asynchronously with internal buffering mechanism to lower impact to main scoring thread\n",
    "streaming_table_name=\"streaming_test\"\n",
    "streaming_collector = Online_Collector(streaming_table_name,ws=ws)\n",
    "\n",
    "import random\n",
    "streaming_collector.start_logging_daemon(buffer_time=2, batch_size=10)\n",
    "\n",
    "for run_id in [\"r000001\", \"r000002\", \"r000003\", \"r000004\", \"r000005\"]:\n",
    "    for i in range(1000):\n",
    "        for lr in [\"0.001\", \"0.002\"]:\n",
    "            df = pd.DataFrame({ \"timestamp\":pd.to_datetime('today'), \"lr\":[lr],\"metric1\":[random.uniform(3,50)] })\n",
    "            streaming_collector.stream_collect_df_queue(df)\n",
    "# streaming_collector.stop_logging_daemon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monitoring.query import RT_Visualization\n",
    "streaming_table_name=\"streaming_test\"\n",
    "rt_viz =RT_Visualization(streaming_table_name,ws)\n",
    "rt_viz.scatter(max_records=200, ago='12h',groupby='lr', y_metric='metric1',x_metric='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"./model-deployment/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(\"data/iris.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "predictions = model.predict(X_test)\n",
    "labels = ['setosa', 'versicolor', 'virginica']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could add logging demo here\n",
    "\n",
    "import datetime\n",
    "df1 = pd.DataFrame()\n",
    "probs = model.predict_proba(X_test)\n",
    "probs = [prob for prob in probs]\n",
    "df1['probs'] = probs\n",
    "preds = model.predict(X_test)\n",
    "df1['pred'] = preds\n",
    "df1['scoring_service'] = \"managed_online\"\n",
    "ts =datetime.datetime.now()\n",
    "df1['timestamp'] = ts\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74e9702761b8f12846716a18132904990016d49f378e22e0e13a0e91318de754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mlopsenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
